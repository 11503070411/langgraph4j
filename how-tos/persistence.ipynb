{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "String userHomeDir = System.getProperty(\"user.home\");\n",
    "String localRespoUrl = \"file://\" + userHomeDir + \"/.m2/repository/\";\n",
    "String langchain4jVersion = \"0.33.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%dependency /add-repo local \\{localRespoUrl} release|never snapshot|always\n",
    "%dependency /list-repos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%dependency /add org.bsc.langgraph4j:langgraph4j-core-jdk8:1.0-SNAPSHOT\n",
    "%dependency /add dev.langchain4j:langchain4j:\\{langchain4jVersion}\n",
    "%dependency /add dev.langchain4j:langchain4j-open-ai:\\{langchain4jVersion}\n",
    "\n",
    "%dependency /resolve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to add persistence (\"memory\") to your graph\n",
    "\n",
    "Many AI applications need memory to share context across multiple interactions. In LangGraph4j, memory is provided for any [`StateGraph`] through [`Checkpointers`].\n",
    "\n",
    "When creating any LangGraph workflow, you can set them up to persist their state by doing using the following:\n",
    "\n",
    "1. A [`Checkpointer`], such as the [`MemorySaver`]\n",
    "1. Pass your [`Checkpointers`] in configuration when compiling the graph.\n",
    "\n",
    "### Example\n",
    "\n",
    "```java\n",
    "\n",
    "AgentStateFactory<AgentState> factory = (initData) -> (new AgentState(initData));\n",
    "\n",
    "var workflow = new StateGraph( factory );\n",
    "\n",
    "// ... Add nodes and edges\n",
    "\n",
    "// Initialize any compatible CheckPointSaver\n",
    "var memory = new MemorySaver();\n",
    "\n",
    "var compileConfig = CompileConfig.builder()\n",
    "                        .checkpointSaver(memory)\n",
    "                        .build();\n",
    "\n",
    "var persistentGraph = workflow.compile( compileConfig );\n",
    "```\n",
    "\n",
    "[`StateGraph`]: https://bsorrentino.github.io/langgraph4j/apidocs/org/bsc/langgraph4j/StateGraph.html\n",
    "[`Checkpointers`]: https://bsorrentino.github.io/langgraph4j/apidocs/org/bsc/langgraph4j/checkpoint/BaseCheckpointSaver.html\n",
    "[`Checkpointer`]: https://bsorrentino.github.io/langgraph4j/apidocs/org/bsc/langgraph4j/checkpoint/Checkpoint.html\n",
    "[`MemorySaver`]: https://bsorrentino.github.io/langgraph4j/apidocs/org/bsc/langgraph4j/checkpoint/MemorySaver.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the state\n",
    "\n",
    "State is an (immutable) data class, inheriting from [`AgentState`], shared with all nodes in our graph. A state is basically a wrapper of a `Map<String,Object>` that provides some enhancers:\n",
    "\n",
    "1. Schema (optional), that is a `Map<String,Channel>` where each [`Channel`] describe behaviour of the related property\n",
    "1. `value()` accessors that inspect Map an return an Optional of value contained and cast to the required type\n",
    "\n",
    "[`Channel`]: https://bsorrentino.github.io/langgraph4j/apidocs/org/bsc/langgraph4j/state/Channel.html\n",
    "[`AgentState`]: https://bsorrentino.github.io/langgraph4j/apidocs/org/bsc/langgraph4j/state/AgentState.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.bsc.langgraph4j.state.AgentState;\n",
    "import org.bsc.langgraph4j.state.Channel;\n",
    "import org.bsc.langgraph4j.state.AppenderChannel;\n",
    "import dev.langchain4j.data.message.AiMessage;\n",
    "import dev.langchain4j.data.message.ChatMessage;\n",
    "\n",
    "public class MessageState extends AgentState {\n",
    "\n",
    "    static Map<String, Channel<?>> SCHEMA = Map.of(\n",
    "            \"messages\", AppenderChannel.<AiMessage>of(ArrayList::new)\n",
    "    );\n",
    "\n",
    "    public MessageState(Map<String, Object> initData) {\n",
    "        super( initData  );\n",
    "    }\n",
    "\n",
    "    List<? extends ChatMessage> messages() {\n",
    "        return this.<List<? extends ChatMessage>>value( \"messages\" )\n",
    "                .orElseThrow( () -> new RuntimeException( \"messages not found\" ) );\n",
    "    }\n",
    "\n",
    "    // utility method to quick access to last message\n",
    "    Optional<? extends ChatMessage> lastMessage() {\n",
    "        List<? extends ChatMessage> messages = messages();\n",
    "        return ( messages.isEmpty() ) ? \n",
    "            Optional.empty() :\n",
    "            Optional.of(messages.get( messages.size() - 1 ));\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Serializer\n",
    "\n",
    "Every object that should be stored into State **MUST BE SERIALIZABLE**. If the object is not `Serializable` by default, Langgraph4j provides a way to build and associate a custom [`Serializer`] to it. \n",
    "\n",
    "In the example, since [`AiMessage`] from Langchain4j is not Serialzable we have to create an register a new custom [`Serializer`].\n",
    "\n",
    "[`Serializer`]: https://bsorrentino.github.io/langgraph4j/apidocs/org/bsc/langgraph4j/serializer/Serializer.html\n",
    "[`AiMessage`]: https://docs.langchain4j.dev/apidocs/dev/langchain4j/data/message/AiMessage.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.bsc.langgraph4j.serializer.Serializer;\n",
    "import org.bsc.langgraph4j.serializer.StateSerializer;\n",
    "import dev.langchain4j.data.message.AiMessage;\n",
    "\n",
    "StateSerializer.INSTANCE.register(AiMessage.class, new Serializer<AiMessage>() {\n",
    "\n",
    "    @Override\n",
    "    public void write(AiMessage object, ObjectOutput out) throws IOException {\n",
    "        out.writeUTF(object.text());\n",
    "    }\n",
    "\n",
    "    @Override\n",
    "    public AiMessage read(ObjectInput in) throws IOException, ClassNotFoundException {\n",
    "        return AiMessage.aiMessage(in.readUTF());\n",
    "    }\n",
    "});\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the tools\n",
    "\n",
    "Using [langchain4j], We will first define the tools we want to use. For this simple example, we will\n",
    "use create a placeholder search engine. However, it is really easy to create\n",
    "your own tools - see documentation\n",
    "[here][tools] on how to do\n",
    "that.\n",
    "\n",
    "[langchain4j]: https://docs.langchain4j.dev\n",
    "[tools]: https://docs.langchain4j.dev/tutorials/tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dev.langchain4j.agent.tool.P;\n",
    "import dev.langchain4j.agent.tool.Tool;\n",
    "\n",
    "import java.util.Optional;\n",
    "\n",
    "import static java.lang.String.format;\n",
    "\n",
    "public class SearchTool {\n",
    "\n",
    "    @Tool(\"Use to surf the web, fetch current information, check the weather, and retrieve other information.\")\n",
    "    String execQuery(@P(\"The query to use in your search.\") String query) {\n",
    "\n",
    "        // This is a placeholder for the actual implementation\n",
    "        return \"Cold, with a low of 13 degrees\";\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the model\n",
    "\n",
    "Now we will load the\n",
    "[chat model].\n",
    "\n",
    "1. It should work with messages. We will represent all agent state in the form of messages, so it needs to be able to work well with them.\n",
    "2. It should work with [tool calling],meaning it can return function arguments in its response.\n",
    "\n",
    "Note:\n",
    "   >\n",
    "   > These model requirements are not general requirements for using LangGraph4j - they are just requirements for this one example.\n",
    "   >\n",
    "\n",
    "[chat model]: https://docs.langchain4j.dev/tutorials/chat-and-language-models\n",
    "[tool calling]: https://docs.langchain4j.dev/tutorials/tools   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dev.langchain4j.model.openai.OpenAiChatModel;\n",
    "import dev.langchain4j.agent.tool.ToolSpecification;\n",
    "import dev.langchain4j.agent.tool.ToolSpecifications;\n",
    "\n",
    "public record LLM( OpenAiChatModel model ) {\n",
    "    public LLM() {\n",
    "        this( \n",
    "            OpenAiChatModel.builder()\n",
    "                .apiKey( System.getenv(\"OPENAI_API_KEY\") )\n",
    "                .modelName( \"gpt-4o\" )\n",
    "                .logResponses(true)\n",
    "                .maxRetries(2)\n",
    "                .temperature(0.0)\n",
    "                .maxTokens(2000)\n",
    "                .build()   \n",
    "            );\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dev.langchain4j.agent.tool.ToolSpecification;\n",
    "import dev.langchain4j.agent.tool.ToolSpecifications;\n",
    "import dev.langchain4j.data.message.UserMessage;\n",
    "import dev.langchain4j.data.message.AiMessage;\n",
    "import dev.langchain4j.model.output.Response;\n",
    "import dev.langchain4j.model.openai.OpenAiChatModel;\n",
    "\n",
    "var llm = new LLM();\n",
    "\n",
    "var tools = ToolSpecifications.toolSpecificationsFrom( SearchTool.class );\n",
    "\n",
    "UserMessage userMessage = UserMessage.from(\"What will the weather be like in London tomorrow?\");\n",
    "Response<AiMessage> response = llm.model().generate(Collections.singletonList(userMessage), tools );\n",
    "AiMessage aiMessage = response.content();\n",
    "\n",
    "System.out.println( aiMessage );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the graph\n",
    "\n",
    "We can now put it all together. We will run it first without a checkpointer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import static org.bsc.langgraph4j.StateGraph.START;\n",
    "import static org.bsc.langgraph4j.StateGraph.END;\n",
    "import org.bsc.langgraph4j.StateGraph;\n",
    "import org.bsc.langgraph4j.action.EdgeAction;\n",
    "import static org.bsc.langgraph4j.action.AsyncEdgeAction.edge_async;\n",
    "import org.bsc.langgraph4j.action.NodeAction;\n",
    "import static org.bsc.langgraph4j.action.AsyncNodeAction.node_async;\n",
    "import dev.langchain4j.data.message.AiMessage;\n",
    "import dev.langchain4j.data.message.ChatMessage;\n",
    "import dev.langchain4j.service.tool.DefaultToolExecutor;\n",
    "\n",
    "// Route Message \n",
    "EdgeAction<MessageState> routeMessage = state -> {\n",
    "  \n",
    "  var lastMessage = state.lastMessage();\n",
    "  \n",
    "  if ( !lastMessage.isPresent()) {\n",
    "    return \"exit\";\n",
    "  }\n",
    "\n",
    "  var message = (AiMessage)lastMessage.get();\n",
    "\n",
    "  // If no tools are called, we can finish (respond to the user)\n",
    "  if ( !message.hasToolExecutionRequests() ) {\n",
    "    return \"exit\";\n",
    "  }\n",
    "  \n",
    "  // Otherwise if there is, we continue and call the tools\n",
    "  return \"next\";\n",
    "};\n",
    "\n",
    "var llm = new LLM();\n",
    "\n",
    "// Call Model\n",
    "NodeAction<MessageState> callModel = state -> {\n",
    "  \n",
    "  var response = llm.model().generate( (List<ChatMessage>)state.messages() );\n",
    "\n",
    "  return Map.of( \"messages\", response.content() );\n",
    "};\n",
    "\n",
    "var searchTool = new SearchTool();\n",
    "\n",
    "\n",
    "// Invoke Tool \n",
    "NodeAction<MessageState> invokeTool = state -> {\n",
    "\n",
    "  var lastMessage = (AiMessage)state.lastMessage()\n",
    "                          .orElseThrow( () -> ( new IllegalStateException( \"last message not found!\")) );\n",
    "\n",
    "  var executionRequest = lastMessage.toolExecutionRequests().get(0);\n",
    "\n",
    "  var executor = new DefaultToolExecutor( searchTool, executionRequest );\n",
    "\n",
    "  var result = executor.execute( executionRequest, null );\n",
    "\n",
    "  return Map.of( \"messages\", AiMessage.from( result ) );\n",
    "};\n",
    "\n",
    "// Define Graph\n",
    "\n",
    "var workflow = new StateGraph<MessageState> ( MessageState.SCHEMA, MessageState::new )\n",
    "  .addNode(\"agent\", node_async(callModel) )\n",
    "  .addNode(\"tools\", node_async(invokeTool) )\n",
    "  .addEdge(START, \"agent\")\n",
    "  .addConditionalEdges(\"agent\", edge_async(routeMessage), Map.of( \"next\", \"tools\", \"exit\", END ))\n",
    "  .addEdge(\"tools\", \"agent\");\n",
    "\n",
    "var graph = workflow.compile();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dev.langchain4j.data.message.AiMessage;\n",
    "\n",
    "\n",
    "Map<String,Object> inputs = Map.of( \"messages\", AiMessage.from(\"Hi I'm Bartolo, niced to meet you.\") );\n",
    "\n",
    "var result = graph.stream( inputs );\n",
    "\n",
    "for( var r : result ) {\n",
    "  System.out.println( r.node() );\n",
    "  System.out.println( r.state() );\n",
    "//   if (msg?.content) {\n",
    "//     console.log(msg.content);\n",
    "//   } else if (msg?.tool_calls?.length > 0) {\n",
    "//     console.log(msg.tool_calls);\n",
    "//   } else {\n",
    "//     console.log(msg);\n",
    "//   }\n",
    "//   console.log(\"-----\\n\");\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n",
      "true\n",
      "true\n",
      "true\n"
     ]
    }
   ],
   "source": [
    "var list = new ArrayList<String>();\n",
    "\n",
    "var value = List.class.isInstance(list);\n",
    "System.out.println( value );\n",
    "value = Collection.class.isInstance(list);\n",
    "System.out.println( value );\n",
    "\n",
    "System.out.println( List.class.isAssignableFrom(ArrayList.class) );\n",
    "System.out.println( Collection.class.isAssignableFrom(ArrayList.class) );\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java (rjk 2.1.0)",
   "language": "java",
   "name": "rapaio-jupyter-kernel"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "java",
   "nbconvert_exporter": "script",
   "pygments_lexer": "java",
   "version": "22.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
